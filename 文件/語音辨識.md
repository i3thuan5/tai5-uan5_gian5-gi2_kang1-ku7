# 語音辨識（Speech Recognition）
語音辨識就是共語音轉做文字，
會當用佇語音指令佮問答系統（親像蘋果公司的Siri）。

這方面的開源工具有[Kaldi](http://kaldi.sourceforge.net/)佮[HTK](http://htk.eng.cam.ac.uk/)

## Kaldi
- [github](https://github.com/kaldi-asr/kaldi)
- [文件](http://kaldi-asr.org/doc/)

### 入手
1. 需Unix，建議使用[Mint Linux](https://www.linuxmint.com/download.php)作業系統
  * Mac需要先走`brew install automake autoconf wget libtool`
2. [裝kaldi](http://kaldi-asr.org/doc/install.html)
   1. 入去`tools` ，而且照`INSTALL`做
   2. 入去`src` ，而且照`INSTALL`做
3. 走範例
   1. 入去`egs/yesno/s5`，照伊的`README`指示
      - `bash run.sh`，幾分鐘內程式會走了
   2. 入去`egs/vystadial_en/s5`，照伊的`README`指示
      - 照家己的需要改`cmd.sh`
      - `bash run.sh`
        - CPU時間需要5000~6000分鐘
   3. `egs/voxforge/s5`，走`bash getdata.sh`佮`time bash -x run.sh`
      - 純CPU時間
        - `real    10081m51.386s`、`user    32927m9.961s`、`sys     294m11.191s`
4. 看[導覽教學](http://kaldi-asr.org/doc/tutorial.html)
   - 伊的例，語料愛錢，所以提第三步的`yesno`佮`vystadial_en`比較
   - `vystadial_en`的`data`資料夾，叫做`lang_prep`
5. 照[資料準備](http://kaldi-asr.org/doc/data_prep.html)
   - 一步一步做
6. 修改範例
   - [taiwanese](https://github.com/sih4sing5hong5/kaldi/tree/taiwanese/egs/taiwanese/s5c)
     - 自`swbd`改的
     - 參考`timit`佮`swbd`的`sgmm2`
   - `egs/voxforge/s5/`的`run.sh`上清氣，較好看
   - `iban` `sgmm2`的`rescore`佮`big lm`
     - 用細lm來`decode`才閣用大lm來`rescore`(15.84%)，不如直接用大lm來`decode`(15.32%)
   - `voxforge`有`mpe`
   - `nnet3`：`wsj`、`swbd`
   - `wsj/s5/local/run_sgmm2.sh` `quinphone`
   - 簡單瞭解各個做法：[2013_interspeech_dnn](http://www.danielpovey.com/files/2013_interspeech_dnn.pdf)
7. 參考文章
   - http://vpanayotov.blogspot.tw/2012/06/kaldi-decoding-graph-construction.html
   - https://sourceforge.net/p/kaldi/discussion/1355347/thread/33098413/?page=0
   - https://sourceforge.net/p/kaldi/discussion/1355348/thread/476965d5/
   

### 其他
* GPU對decoding較無效果
  * https://groups.google.com/d/msg/kaldi-help/cXUxiXDAJUs/fnFGFSTnBgAJ
  * https://groups.google.com/forum/#!topic/kaldi-help/Zujqc0ishQU
* jobs佮thread設定
  * https://groups.google.com/forum/#!msg/kaldi-help/kTDwa48u2PM/M5qMYGPVCwAJ
* globalphone model
  * https://groups.google.com/forum/#!msg/kaldi-help/ifUe6IuGdFc/PkF5j1atCwAJ
* rnnlm
  * https://groups.google.com/forum/#!topic/kaldi-help/018JjvRBz-M
  * https://groups.google.com/forum/#!msg/kaldi-help/csJrMoGwEpU/gZQDveHLCwAJ
* acwt參數
  * https://groups.google.com/forum/#!topic/kaldi-developers/IBhn9ndmjQI
* 入門文章
  * https://groups.google.com/forum/#!msg/kaldi-help/3LBSzmploC0/xDPK2vuXDgAJ
  * https://groups.google.com/d/msg/kaldi-help/3LBSzmploC0/ff35yEUqEgAJ
* lattice
  * https://groups.google.com/forum/#!topic/kaldi-help/cXX7y3Hvf3w
  * https://groups.google.com/forum/#!topic/kaldi-help/QqUQoX816GE
  * https://groups.google.com/forum/#!topic/kaldi-help/UiVD5WPA8fI
* 錄音相關
  * https://groups.google.com/forum/#!msg/kaldi-help/gBRw7svAQHs/39MuJdu3AAAJ
* https://sourceforge.net/p/kaldi/discussion/1355348/thread/c99fe7a6/?limit=25


### 訓練語料準備
#### 唐鳳的建議
##### 音檔編碼格式

* flac
* opus
  * watson IBM在用
* aac

訊號完整度（對辨識的影響）：`flac`>`opus`>`aac`

##### 錄音流程
1. 準備萬字表，而且準備做一段一段。一段的長度，是一般人唸了需要啉茶歇睏的長度
2. 揣發音人，一直予伊唸，一段存一个音檔
3. 轉去實驗室，共音檔佮萬字表alignment

##### 補錄語料
若是拄著辨識錯誤，袂共這个音檔當做訓練語料，會分析是佗位錯誤，若是是腔口的問題，就去錄彼腔口的聲音


#### 訓練語料過濾
若是訓練語料無夠清氣，會當用`steps/cleanup/clean_and_segment_data.sh`

##### 會切音檔
```
tong0000292-0002921無註明-ku0002921 因-為｜in1-ui7 原-地｜guan5-te7 有｜u7 水｜tsui2 go2｜go2 到｜kah8 水-源｜tsui2-guan5
tong0000292-0002921無註明-ku0002921-1 因-為｜in1-ui7 原-地｜guan5-te7 有｜u7
tong0000292-0002921無註明-ku0002921-2 水-源｜tsui2-guan5

tong0000292-0002921無註明-ku0002921 tong0000292 7082.32000000001 7085.32800000001
tong0000292-0002921無註明-ku0002921-1 tong0000292 7082.32 7083.63
tong0000292-0002921無註明-ku0002921-2 tong0000292 7084.4 7085.33
```

雖然原本的音檔就誠好矣，毋過新的兩个音檔切了閣袂bai2

##### 調時間
```
tong0016578-0000000無註明-ku0000000 tong0016578 0 2.115918367346939
tong0016578-0000000無註明-ku0000000-1 tong0016578 0.74 1.905
```
- 毋過會切毋著 https://github.com/sih4sing5hong5/tai5-uan5_gian5-gi2_hok8-bu7/issues/134

##### 加`<UNK>`
```
tong0000004-0000002朝森-ku0000604 講-了｜kong2-liau2 誠-好｜tsiann5-ho2
tong0000004-0000002朝森-ku0000604-1 <UNK> 講-了｜kong2-liau2 誠-好｜tsiann5-ho2

tong0000027-0000011阿婆-ku0000012 曷｜ah8 是｜si7 按-怎｜an2-nua2 今-仔-日｜kin1-a2-jit8 是｜si7 啥-物｜siann2-mih8 日-子｜jit8-tsi2 按-呢｜an2-ne1 tsiah10｜tsiah10 食｜tsiah8 好｜ho2
tong0000027-0000011阿婆-ku0000012-1 <UNK> 啥-物｜siann2-mih8 日-子｜jit8-tsi2 按-呢｜an2-ne1 tsiah10｜tsiah10 食｜tsiah8 好｜ho2
```
`tong0000004-0000002朝森-ku0000604`頭前有華語`學長`

##### 綜合三个
```
tong0000292-0003393無註明-ku0003393 佇｜ti7 茫-茫｜bang5-bang5 的｜e5 人｜lang5 先｜sing1 路-途｜loo7-too5
tong0000292-0003393無註明-ku0003393-1 佇｜ti7 茫-茫｜bang5-bang5 的｜e5
tong0000292-0003393無註明-ku0003393-2 <UNK> 先｜sing1 路-途｜loo7-too5

tong0000292-0003393無註明-ku0003393 tong0000292 8147.24800000001 8150.0480000000
tong0000292-0003393無註明-ku0003393-1 tong0000292 8147.25 8148.62
tong0000292-0003393無註明-ku0003393-2 tong0000292 8148.88 8150.04
```
∵是`jin5`毋是`lang5`


### 討論紀錄
變調、漢字臺羅
我看著的羅馬字大部份攏有標調
華語免標注音，是因為有漢字就有法度標注音
臺語的漢字佮羅馬字才整合無偌久
實務上有需要兩个做伙做

Combine001/Combine001_0010.wav	伊_攏_是_恬_恬_仔_搰_力_去_做_//i2 long1-si3 diam3-diam3-a1 gut1-lat2 ki1-zor3 
我的做伙是共漢字佮羅馬字做一个詞
Combine001/Combine001_0010.wav	伊｜i2 攏-是｜long1-si3 恬-恬-仔｜diam3-diam3-a1 搰-力｜gut1-lat2 去-做｜ki1-zor3

換做臺羅拼音是：
伊｜i1 攏-是｜long2-si7 恬-恬-仔｜tiam7-tiam7-a2 搰-力｜kut4-lat4 去-做｜khi3-tso7

我佇lexcicon.txt辭典內底共in拆開
伊｜i1 ʔ- i1
攏-是｜long2-si7 l- o2 ŋ2 s- i7
恬-恬-仔｜tiam7-tiam7-a2 t- i7 a7 m7 t- i7 a7 m7 ʔ- a2
…

kaldi有共辭典獨立出來，變調只要改lexcicon.txt就好
伊｜i1 ʔ- i1 #無變調
伊｜i1 ʔ- i7 #變調
攏-是｜long2-si7 l- o1 ŋ1 s- i7 #頭字變，尾字無變
攏-是｜long2-si7 l- o1 ŋ1 s- i3 #頭字變，尾字變調

我lm的文本，大部份的原始來源攏是漢羅
所以轉做`攏-是｜long2-si7`這種分詞格式是必要的



pang聲韻會在辭典拆成 p ang
音素會拆成 p a  ng

華語之前 有人這樣做

好像是 Microsoft

但 近幾年 都是用 p ang2



我試perplexity的結果是這樣：

$ ngram -lm data/local/lm/語言模型.lm -ppl text_tshi3.txt
data/local/lm/語言模型.lm: line 7: warning: non-zero probability for <unk> in closed-vocabulary LM
file text_tshi3.txt: 277 sentences, 1135 words, 0 OOVs
0 zeroprobs, logprob= -5321.24 ppl= 5869.24 ppl1= 48788.2

通常英文的ppl 在 100左右

中文大約在200





帶聲調的音節，應是 2500 左右。
詳細數字要看採用的文字語料中【相異】的語言單位之數量。


辨識單位 |Ngram| Perplexity 
---------|-----| ---------- 
文(Ch) | 0g | 3426 
文(Ch) | 7g | 37 
音(Ts) | 0g | 2441 
音(Ts) | 7g | 45

以上是TwESC01 (朗讀140篇)10萬字左右做出來的結果。


其中 3426 恰好是10萬字中，相異的漢羅字數；2441恰好是相異的聲調音節數。



```
通常 如果 是 inside 語言模型 在中文
四組分別加入我要測的東西，做inside test，看好壞有沒有差很多？
Character error rate 大約在5%
3 gram


用 去聲調的音節 做成 1gram 的語言模型
看看辨識結果如何
應該正確率要差不多 50-60之間
```


## HTK
臺灣言語工具捌共HTK的功能包起來，毋過這馬無按算閣維護辨識的部份矣，請看[原因](https://github.com/sih4sing5hong5/tai5-uan5_gian5-gi2_hok8-bu7/pull/113)。

### 套件準備
```bash
sudo apt-get install -y libc6-dev-i386 linux-libc-dev gcc-multilib libx11-dev libx11-dev:i386
```

### 安裝
執行`python`，而且輸入
```python3
from 臺灣言語工具.語音辨識.HTK工具.安裝HTK語音辨識程式 import 安裝HTK語音辨識程式
安裝HTK語音辨識程式.安裝htk()
```

### 標文本的時間
若是有音檔佮對應的文本音標，會使標出逐個語詞佇音檔的時間
```python3
對齊標仔目錄 = HTK辨識模型訓練.加短恬閣對齊(
    音檔目錄, 標仔目錄, 音節聲韻對照檔, 模型暫存目錄
)
```

#### 標仔格式說明
以`試驗/語音辨識/語音語料/labels`的資料為例
標仔`刀石`應該生做，其中`sil`表示音檔前後有一段空白無聲
```
sil
to
tsioh
sil
```

#### 音檔格式說明
以`試驗/語音辨識/語音語料/wav`的資料為例
愛準備對應標仔檔名的wav檔案

#### 音節聲韻對照檔格式說明
這個檔案的目的是予HTK會當用聲韻，閣較細的單位來辨識，增加準度

以`試驗/語音辨識/語音語料/聲韻對照.dict`的資料為例
```
a	ʔ a
ah	ʔ aʔ
ai	ʔ ai
aih	ʔ aiʔ
……
```
第一逝代表`a`會當拆做`ʔ`佮`a`
第二逝代表`ah`會當拆做`ʔ`佮`aʔ`
以此類推…

#### 輸出標仔格式
走面頂的程式了，會得著有標時間的標仔檔
```
0 2100000 sil
2100000 5500000 to
5500000 9300000 tsioh
9300000 11100000 sil
```

### 辨識任意音檔
```python3
from 臺灣言語工具.語音辨識.HTK工具.HTK辨識模型訓練 import HTK辨識模型訓練
from 臺灣言語工具.語音辨識.HTK工具.HTK語料處理 import HTK語料處理
from 臺灣言語工具.語音辨識.HTK工具.HTK辨識模型 import HTK辨識模型
# 訓練模型
三連音辨識模型 = HTK辨識模型訓練.訓練三連音辨識模型(
    音檔目錄, 標仔目錄, 音節聲韻對照檔, 模型暫存目錄
)
# 辨識音檔
特徵檔 = HTK語料處理.產生特徵檔(音檔所在, 暫存目錄)
三連音辨識模型.辨識音節(特徵檔, 結果暫存目錄, 3)
# 儲存模型、載入
三連音辨識模型.存資料佇(模型目錄)
三連音辨識模型 = HTK辨識模型(模型目錄)
```

### 合成聲音
├── 語音合成
│   ├── HTS工具
│   │   ├── HTS合成模型.py
│   │   └── __init__.py
│   ├── 生決策樹仔問題.py
│   ├── 語音標仔轉換.py
│   ├── 調音盒.py
│   └── 閩南語變調.py

## HTK原理

HTK是揣出語音佮音標的對應，
共語音轉做一个一个MFCC聲學特徵，
主要是用高斯混合模型去判斷是佇一个音標。

用隱性馬可夫模型（HMM）來模擬語音狀態的變化，
解決語音訊號連續閣無固定長度的問題。

### 模型訓練流程
#### 一般模型
1. 建立初步模型
  * 假設逐個音的GMM高斯混合模型參數攏仝款
2. 模型重估
  * 用[EM算法](https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95)切音，而且統計逐個音的參數

#### 加短恬模型
有的音節中央可能無聲音，所以佇中央加`sp短恬`，增加辨識度

1. 建立一般模型
2. 佇音節標仔中央加`sp短恬`
3. 模型佮標仔類檔嘛加`sp短恬`
4. 模型重估
5. 用模型切音，若`sp短恬`傷短，代表音節中央有聲，所以提掉
6. 模型重估

#### 三連音模型
原本的模型攏是考慮`音`本身（mono-phone）的參數，
若是為著提懸辨識度，考慮音的前後音（Context-Sensitive），
`前-音-後`三連音（tri-phone）。
毋過按呢模型會上濟，
就會用決策樹，合併相倚的高斯模型。

1. 建立加短恬模型
2. 模型佮標仔轉做三連音
3. 模型重估
4. 用決策樹，共相倚的三連音，因的高斯模型縛做伙
  * 合併相像的模型，按呢樣本數較濟，訓練較準
5. 模型閣重估

#### 其他
佇`HTK辨識模型訓練.py`內底，會當看著訓練模型了，
閣會`加混合數`，是予高斯混合模型有較濟的平均點，增加辨識度。
